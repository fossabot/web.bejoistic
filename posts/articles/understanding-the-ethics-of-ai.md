---
title: Understanding the Ethics of AI
subtitle: "AI is fast becoming a standard part of the technology landscape for many organizations."
description: "AI is fast becoming a standard part of the technology landscape for many organizations."
slug: understanding-the-ethics-of-ai
date: 2020-06-04
tags: ["article", "ai", "ethics"]
layout: layouts/post.njk
permalink: /articles/{{ slug }}/index.html
---

In 2018, Elaine Herzberg was killed in what is believed to be [the first pedestrian fatality](https://www.forbes.com/sites/cognitiveworld/2019/09/26/what-happens-with-self-driving-cars-kill-people/#5bbe1d5b405c) by an [autonomous vehicle](https://www.twi-global.com/technical-knowledge/faqs/what-is-an-autonomous-vehicle). The incident caught the world’s attention and shone a light on the ethics of AI.

The death of Elaine Herzberg was shocking because it raised questions about whether we could trust Artificial Intelligence (AI) with something as important as our lives. But what does that mean for businesses looking to exploit this technology? The [World Economic Forum](https://www.weforum.org/agenda/2019/06/4-steps-to-developing-responsible-ai/) (WEF) calls this responsible AI and research has shown that organizations are increasingly concerned about the implications of AI.

As [Angel Gurria](https://www.london.edu/think/iie-ai-significant-potential-but-ethics-must-be-the-starting-point-says-oecd), Secretary-General of the Organization for Economic Co-Operation and Development (OECD) commented, “To realize the full potential of AI technology, we need one critical ingredient. That critical ingredient is trust.”

## Defining the ethics of AI

We’ve witnessed quite a lot of concern from the likes of [Tesla’s Elon Musk](https://www.theverge.com/2020/2/18/21142489/elon-musk-ai-regulation-tweets-open-ai-tesla-spacex-twitter) about AI’s potential for damage. The good news is that AI is not about to reach a state of [general intelligence](https://www.forbes.com/sites/cognitiveworld/2019/06/10/how-far-are-we-from-achieving-artificial-general-intelligence/#376dcf1f6dc4) – where machines can understand and learn just like humans – any time soon. In the meantime, it remains a tool created by humans to support human activity.

AI – especially machine learning – works by taking data inputs, learning something from the data and, from that, inferring something to make predictions.

This raises the issue of how we judge whether an output from an AI system is safe and will not succumb to bias or cause any harm. That is the crux of the ethics of AI.

How does the AI developer teach and help its autonomous vehicle to make a decision in the event of an accident? Should the AI prioritize the protection of its passengers or the people outside the vehicle?

Determining whether an outcome is ethically acceptable can raise reasonable disagreements. In this period of COVID-19, physicians, politicians, and the public may disagree on the ethics around healthcare decisions like prioritizing ventilators for between the young instead of the older patients. If humans can disagree, how can an AI do better?

In a business setting where AI is being used to automate processes or improve the customer experience, the ethics may seem slightly less important. But, for all organizations, the major purpose of AI will be to deliver insight that improves decision-making. So, being able to trust and rely on that information is essential.

In a recent [Accenture research](https://www.accenture.com/t20180919T202227Z__w__/us-en/_acnmedia/PDF-86/Accenture-AI-Momentum-Final.pdf) report, over 90% of the most successful AI deployment had a focus on ethics – compared with under half of the least successful deployments.

## Key issues within the ethics of AI

There are many ethical questions about the societal impact of AI, and if you are interested If I’d recommend the excellent [Hitchhiker’s Guide to AI Ethics](https://towardsdatascience.com/the-hitchhikers-guide-to-ai-ethics-part-3-what-ai-does-its-impact-c27b9106427a). For now, I am specifically going to concentrate on the ethics of creating AI solutions within a business environment.

### Bias

The area of ethics that has perhaps received the greatest attention is bias, when skewed data models or developer prejudice unintentionally creeps into the AI system. Even giants like Apple and Goldman Sachs have fallen foul with the [Apple Card](https://www.nytimes.com/2019/11/10/business/Apple-credit-card-investigation.html) accused of gender bias. This isn’t surprising when you consider that there are [188 different cognitive biases](https://www.visualcapitalist.com/every-single-cognitive-bias/). Whether an unconscious prejudice of the AI system creator or a bias built into the data model the system uses, the results will be that the outputs are likely to be unfair, discriminatory or just plain wrong.

### Accountability and explainability

The concepts of accountability and explainability are well understood in everyday life. If you are responsible for something, then you should be able to explain why it happened. The same is true in the world of AI. It’s essential that any actions that AI takes can be fully explained and audited. It has to be able to be held accountable.

### Transparency

To be accountable, the AI system has to be transparent. However, many AI solutions take a ‘black box’ approach that doesn’t allow visibility of the underlying algorithms. This can be because the algorithms are incredibly complex but often it’s down to the vendor wishing to protect its own intellectual property.

### Data assurance

A key point in the creation of AI systems is how you work with the data – especially personal data – used to populate your models. Machine learning, and deep learning, requires huge data sets to learn and improve. The more data, the better the outcomes over time. However, privacy legislation – such as [GDPR](https://ico.org.uk/about-the-ico/news-and-events/ai-blog-data-protection-impact-assessments-and-ai/) or [CCPA](https://www.forbes.com/sites/tomtaulli/2019/12/27/ccpa--what-does-it-mean-for-ai-artificial-intelligence/#1ac45c056bb2) – imposes new levels of responsibility on organizations about how they capture, store, use, share and report the personal data they hold. You need to be aware of how and why you’re processing the data and the risks involved.

## Establishing ethics in your AI capabilities

Even if you have a team of experienced data scientists in your organization, many of the ethical challenges will still be relatively new. It’s good practice to establish a steering team from across the business, and put in place an ethical framework that outlines what the AI is meant to do, how it should be created and what the expected outcomes are.
